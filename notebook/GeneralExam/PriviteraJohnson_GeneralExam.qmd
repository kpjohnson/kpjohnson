---
title: "Privitera-Johnson General Exam"
author: "Kristin Privitera-Johnson"
format: 
  revealjs:
    theme: dark
    chalkboard:
      src: chalkboard.json
date: "2023-03-16"
categories: ["SAFS", "General Exam"]
---

# Producing scientific advice in a changing world

A working title

## Motivation

```{r, eval=FALSE}

# load ggvenn package
library("ggvenn")

# use data frame as input
# use data.frame as input
d <- tibble(value = c(1, 2, 3, 5, 6, 7, 8, 9),
            `Cultural` = c(TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, TRUE),
            `Conservation` = c(TRUE, FALSE, FALSE, TRUE, FALSE, FALSE, FALSE, TRUE),
            `Economics` = c(TRUE, TRUE, FALSE, FALSE, FALSE, FALSE, TRUE, TRUE),
            `Recreation` = c(FALSE, FALSE, FALSE, FALSE, TRUE, TRUE, FALSE, FALSE))

p <- ggplot(d) +
  geom_venn(aes(A = `Cultural`, B = `Conservation`, C = `Economics`, D = `Recreation`), 
            show_percentage = FALSE,
            fill_color=c("#a6cee3", "#1f78b4", "#b2df8a", "#33a02c"),
            text_size=0,
            set_name_size=5,
            set_name_color="white",
            stroke_color="white") +
  coord_fixed() +
  theme_void()

ggsave('dissertVD.png', p, bg='transparent')

```

![](dissertVD.png){fig-align="center"}

## Scientific Motivation

How do you know when you're successful? From a single-species point-of-view you may want to know things like:

::: incremental
-   Reference points:
    -   What is B and/or F?
    -   How does B and/or F compare to historical B and/or F?
-   Population dynamics:
    -   How do B and F influence average net production rates?
    -   How do components of net production vary over time?
:::

## Broad research questions pt. 1

![](oldthemes.png){fig-align="center"}

## Broad research questions pt. 2

"All models are wrong but some are useful"

::: incremental
-   How can analysts leverage this principle to evaluate management strategies?
-   How can modelling efforts influence management outcomes?
-   How have some of these modelling efforts lead to surprising management outcomes?
    -   What did analysts learn from these surprises (and apply that to future modelling)?
:::

## Chapter Themes

::: incremental
-   Ch. 1: Phase-in HCR et al.
-   Ch. 2: Assessment frequency vs. increasing scientific uncertainty buffers
-   Ch. 3: Incorporating multimodel inference into a climate-linked MSE framework
-   Ch. 4: MSE Interviews
:::

## Chapters 1-2 Status Updates

::: incremental
-   Ch. 1: Phase-in HCR et al.
    -   Analysis ongoing.
    -   Target dates end of academic year
-   Ch. 2: Assessment frequency vs. increasing scientific uncertainty buffers
    -   Toy model stage.
    -   Target date 2023-2024 Academic Year
:::

## Chapters 3-4 Status Updates

::: incremental
-   Ch. 3: Incorporating multimodel inference into a climate-linked MSE framework
    -   Theoretical stage.
    -   Target date 2023-2024 Academic Year or 2024 calendar year
-   Ch. 4: MSE Interviews
    -   Exploring semi-structured interviews.
    -   Target date End of 2023 calendar year
:::

# Chapter 1

## Ch. 1 Questions

::: incremental
-   What happens to management quantities of interest when catch stability mechanisms are used to minimize interannual variation in catch when new stock assessments result in a major increase or decrease in the overfishing limit?
-   How well do phase-in and catch limit restraints perform when a new assessment model leads to changes in the estimates of natural mortality, stock-recruit steepness, catch history, and selectivity form for long- and short-lived stocks?
:::

## Methods Breakdown

![](Ch.%201%20MSE%20Figure.png){fig-align="center"}

## Simulation Design {.smaller}

![](ch1_exp_table.png){fig-align="center"}

## Catch Stability Mechanisms

![](ch1_csm.png){fig-align="center"}

## Updating the phase-in HCR

::: incremental
![](phasein_before.png){fig-align="center"}

![](ch1_phase_pt1.png)
![](ch1_phase_pt2.png){fig-align="center"}

![](ch1_phase_pt3.png){fig-align="center"}
:::

## MSE performance metrics

![](ch1_perf_metrics.png){fig-align="center"}

# Chapter 2

## Ch. 2 Questions

::: incremental

- What are the potential costs associated with lost yield relative to the cost of conducting another assessment within a ten-year assessment interval?

- How does assessment bias (by way of assessment frequency and increasing scientific uncertainty buffers) influence management quantities of interest for various levels of attained catch for target and nontarget stocks?
    - Catch limits are taken completely (100% attainment)
    - Catch limits are less than the Annual Catch Limits
    - Catch limits are set for a stock that interacts with another stock
:::

##

![](ch2diagram.png){fig-align="center"} 

## Comparisons to be made 

::: incremental
- a baseline time series generated with annual assessments and no increasing scientific uncertainty buffers

with increasing scientific uncertainty buffers: 

- time series generated with new assessments every 2 years 
- time series with new assessments every 5 years 
- time series with a new assessment in the tenth year

:::

# Chapter 3

## Ch. 3 Questions

::: incremental
-   Can an ensemble modeling approach mitigate the consequences of model misspecification associated with selecting a single climate model for forecasts and assessments?
-   Does it matter where along the MSE process the ensemble modeling takes place? i.e., How do the reference points change when
  - a single estimation method using model output from an ensemble of climate models
  - an ensemble of estimation method output consisting of one estimation method for each climate model
:::

## Methods Breakdown

![](ch3diagram.png){fig-align="center"} 

## Simulation Design ![](ch3exptable.png){fig-align="center"} 

## Bayesian model-based weights: Spence et al.
![](ch3spence.png) 

## Bayesian model-based weights pt. 2 
![](ch3spencediagram.png){fig-align="center"} 

## Potential HCRs 

![](ch3_HCR_pt1.png){fig-align="center"} 

![](ch3_HCR_pt2.png){fig-align="center"} 

# Chapter 4

## Ch. 4 Questions

::: incremental
-   Which factors influence the range of uncertainties addressed in an MSE?
-   What are examples of implemented meta-rules for tactical MSEs?
-   Which jurisdictions have conducted multiple MSEs for a fishery?
-   Which uncertainties were addressed in each MSE and why?
-   Are there common factors that influence the use of insufficient ranges of uncertainty when performance was inadequate or subsequent monitoring results were surprising?
:::

## Methods Breakdown

-   To summarize which uncertainties were prioritized in the surveyed MSEs and how the range of uncertainties addressed changed over time and over multiple applications of MSEs and/or meta-rules for a single fishery, when applicable.

## Interview themes
![](ch4interviewthemes.png){fig-align="center"}

# Continued discussion 
